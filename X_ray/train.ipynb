{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import resnet50\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import cv2\n",
    "from cv2 import imread\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc(values,model_name='Model'):\n",
    "    labels = ['loss','accuracy']\n",
    "    colors = ['#1f77b4', '#2ca02c']\n",
    "    plt.figure(figsize=(5,1.2))\n",
    "    plt.table(cellText=[[labels[0],\"{:.4f}\".format(values[0])], [labels[1], \"{:.2%}\".format(values[1])]],\n",
    "            colWidths=[0.8, 0.8],\n",
    "            cellLoc='center',\n",
    "            loc='center',\n",
    "            cellColours=[['lightgrey', colors[0]], ['lightgrey', colors[1]]])\n",
    "    plt.title(model_name+' Loss and Accuracy',y=0.7)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout() \n",
    "\n",
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('Cross Entropy Loss')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[\"accuracy\"],'r-x', label=\"Train Accuracy\")\n",
    "    ax.plot(history.history[\"val_accuracy\"],'b-x', label=\"Validation Accuracy\")\n",
    "    ax.legend()\n",
    "    ax.set_title('Accuracy')\n",
    "    ax.grid(True)\n",
    "\n",
    "def display_roc(roc_auc , fpr, tpr, class_num, model_name=''):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(class_num):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve (class {}) (AUC = {:.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')                                                                                                                   \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve of {}'.format(model_name))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiclass_roc(model, x_test, y_test, class_num, model_name='', show=True):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    y_test = keras.utils.to_categorical(y_test, class_num)\n",
    "\n",
    "\n",
    "    y_pred = model.predict(x_test).astype('float32')\n",
    "    print(y_test.shape)\n",
    "    print(y_pred.shape)\n",
    "    for i in range(class_num):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_pred[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    if show:    display_roc(roc_auc,fpr,tpr,class_num,model_name)\n",
    "    else: return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102869336/102869336 [==============================] - 23s 0us/step\n",
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (Ba  (None, 56, 56, 64)           256       ['pool1_pool[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (  (None, 56, 56, 64)           0         ['conv2_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4096      ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_conv[0][0]', \n",
      "                                                                     'conv2_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 28, 28, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 28, 28, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 28, 28, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 28, 28, 256)          0         ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 28, 28, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)      (None, 28, 28, 256)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (Ba  (None, 28, 28, 256)          1024      ['conv2_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (  (None, 28, 28, 256)          0         ['conv3_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32768     ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_conv[0][0]', \n",
      "                                                                     'conv3_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 14, 14, 128)          147456    ['conv3_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 14, 14, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 14, 14, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 512)          0         ['conv3_block3_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 14, 14, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)      (None, 14, 14, 512)          0         ['max_pooling2d_1[0][0]',     \n",
      "                                                                     'conv3_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (Ba  (None, 14, 14, 512)          2048      ['conv3_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (  (None, 14, 14, 512)          0         ['conv4_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131072    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_conv[0][0]', \n",
      "                                                                     'conv4_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block5_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block5_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block5_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block5_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block5_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block6_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block6_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block6_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block6_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 1024)           0         ['conv4_block5_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)      (None, 7, 7, 1024)           0         ['max_pooling2d_2[0][0]',     \n",
      "                                                                     'conv4_block6_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block6_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (  (None, 7, 7, 1024)           0         ['conv5_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524288    ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_conv[0][0]', \n",
      "                                                                     'conv5_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (Ba  (None, 7, 7, 2048)           8192      ['conv5_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (  (None, 7, 7, 2048)           0         ['conv5_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1048576   ['conv5_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (Ba  (None, 7, 7, 2048)           8192      ['conv5_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (  (None, 7, 7, 2048)           0         ['conv5_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1048576   ['conv5_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalizatio  (None, 7, 7, 2048)           8192      ['conv5_block3_out[0][0]']    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " post_relu (Activation)      (None, 7, 7, 2048)           0         ['post_bn[0][0]']             \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['post_relu[0][0]']           \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " predictions (Dense)         (None, 1000)                 2049000   ['avg_pool[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25613800 (97.71 MB)\n",
      "Trainable params: 25568360 (97.54 MB)\n",
      "Non-trainable params: 45440 (177.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50V2\n",
    "\n",
    "resnet50_model = ResNet50V2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\"\n",
    ")\n",
    "resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 224, 224, 64)      256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 224, 224, 64)      256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 112, 112, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 112, 112, 128)     512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 112, 112, 128)     512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 56, 56, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 56, 56, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 56, 56, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 56, 56, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 28, 28, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 28, 28, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 28, 28, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 28, 28, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 14, 14, 512)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 14, 14, 512)       2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 7, 7, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 4096)              16384     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 4096)              16384     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138407208 (527.98 MB)\n",
      "Trainable params: 138382376 (527.89 MB)\n",
      "Non-trainable params: 24832 (97.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "l2_weight = 0.0001\n",
    "\n",
    "model_vgg16 = Sequential(name='VGG16')\n",
    "\n",
    "# Input\n",
    "model_vgg16.add(Input(shape=(224, 224, 3)))  # Assuming input shape of (224, 224, 3)\n",
    "\n",
    "# Block 1\n",
    "model_vgg16.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model_vgg16.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model_vgg16.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model_vgg16.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model_vgg16.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Flatten\n",
    "model_vgg16.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model_vgg16.add(Dense(4096, activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Dense(4096, activation='relu', kernel_regularizer=l2(l2_weight)))\n",
    "model_vgg16.add(BatchNormalization())\n",
    "model_vgg16.add(Dense(1000, activation='softmax'))  # Assuming 1000 classes\n",
    "\n",
    "# Display summary\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='model12.keras', \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True, \n",
    "    verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.8, \n",
    "    patience=2, \n",
    "    min_lr=0.00001)\n",
    "\n",
    "batch_size = 64\n",
    "epoch = 80\n",
    "opt = Adam(learning_rate=0.0004)\n",
    "\n",
    "model_vgg16.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "start = time()\n",
    "history_vgg = model_vgg16.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epoch,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "vgg_time = time() - start\n",
    "saved_model12 = load_model('vgg_xray.keras')\n",
    "plot_loss_accuracy(history_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImageWidth</th>\n",
       "      <th>OriginalImageHeight</th>\n",
       "      <th>OriginalImagePixelSpacing_x</th>\n",
       "      <th>OriginalImagePixelSpacing_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000013_005.png</td>\n",
       "      <td>Emphysema|Infiltration|Pleural_Thickening|Pneu...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>060Y</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000013_026.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>057Y</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000017_001.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>077Y</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000030_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>079Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000032_001.png</td>\n",
       "      <td>Cardiomegaly|Edema|Effusion</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>055Y</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index                                     Finding Labels  \\\n",
       "0  00000013_005.png  Emphysema|Infiltration|Pleural_Thickening|Pneu...   \n",
       "1  00000013_026.png                             Cardiomegaly|Emphysema   \n",
       "2  00000017_001.png                                         No Finding   \n",
       "3  00000030_001.png                                        Atelectasis   \n",
       "4  00000032_001.png                        Cardiomegaly|Edema|Effusion   \n",
       "\n",
       "   Follow-up #  Patient ID Patient Age Patient Gender View Position  \\\n",
       "0            5          13        060Y              M            AP   \n",
       "1           26          13        057Y              M            AP   \n",
       "2            1          17        077Y              M            AP   \n",
       "3            1          30        079Y              M            PA   \n",
       "4            1          32        055Y              F            AP   \n",
       "\n",
       "   OriginalImageWidth  OriginalImageHeight  OriginalImagePixelSpacing_x  \\\n",
       "0                3056                 2544                        0.139   \n",
       "1                2500                 2048                        0.168   \n",
       "2                2500                 2048                        0.168   \n",
       "3                2992                 2991                        0.143   \n",
       "4                2500                 2048                        0.168   \n",
       "\n",
       "   OriginalImagePixelSpacing_y  \n",
       "0                        0.139  \n",
       "1                        0.168  \n",
       "2                        0.168  \n",
       "3                        0.143  \n",
       "4                        0.168  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sample_labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Finding Labels\n",
       "No Finding                                                3044\n",
       "Infiltration                                               503\n",
       "Effusion                                                   203\n",
       "Atelectasis                                                192\n",
       "Nodule                                                     144\n",
       "                                                          ... \n",
       "Atelectasis|Edema|Effusion|Infiltration|Pneumonia            1\n",
       "Atelectasis|Consolidation|Edema|Infiltration|Pneumonia       1\n",
       "Atelectasis|Effusion|Hernia                                  1\n",
       "Atelectasis|Hernia|Pneumothorax                              1\n",
       "Cardiomegaly|Effusion|Emphysema                              1\n",
       "Name: count, Length: 244, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Finding Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = df['Finding Labels'].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Labels (14): ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImageWidth</th>\n",
       "      <th>OriginalImageHeight</th>\n",
       "      <th>OriginalImagePixelSpacing_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>00029721_000.png</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>29721</td>\n",
       "      <td>056Y</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>00026843_001.png</td>\n",
       "      <td>Effusion|Mass</td>\n",
       "      <td>1</td>\n",
       "      <td>26843</td>\n",
       "      <td>058Y</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>00011355_018.png</td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>11355</td>\n",
       "      <td>035Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.194311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image Index Finding Labels  Follow-up #  Patient ID Patient Age  \\\n",
       "5460  00029721_000.png                           0       29721        056Y   \n",
       "5056  00026843_001.png  Effusion|Mass            1       26843        058Y   \n",
       "2194  00011355_018.png                          18       11355        035Y   \n",
       "\n",
       "     Patient Gender View Position  OriginalImageWidth  OriginalImageHeight  \\\n",
       "5460              F            AP                3056                 2544   \n",
       "5056              F            AP                3056                 2544   \n",
       "2194              M            PA                2021                 2021   \n",
       "\n",
       "      OriginalImagePixelSpacing_x  ...  Effusion  Emphysema  Fibrosis  Hernia  \\\n",
       "5460                     0.139000  ...       0.0        0.0       0.0     0.0   \n",
       "5056                     0.139000  ...       1.0        0.0       0.0     0.0   \n",
       "2194                     0.194311  ...       0.0        0.0       0.0     0.0   \n",
       "\n",
       "      Infiltration  Mass  Nodule  Pleural_Thickening  Pneumonia  Pneumothorax  \n",
       "5460           0.0   0.0     0.0                 0.0        0.0           0.0  \n",
       "5056           0.0   1.0     0.0                 0.0        0.0           0.0  \n",
       "2194           0.0   0.0     0.0                 0.0        0.0           0.0  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Finding Labels'] = df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        df[c_label] = df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atelectasis\n",
       "0.0    5098\n",
       "1.0     508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "df['Atelectasis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Labels (0) []\n"
     ]
    }
   ],
   "source": [
    "MIN_CASES = 1000\n",
    "all_labels = [c_label for c_label in all_labels if df[c_label].sum()>MIN_CASES]\n",
    "print('Clean Labels ({})'.format(len(all_labels)), \n",
    "      [(c_label,int(df[c_label].sum())) for c_label in all_labels])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
