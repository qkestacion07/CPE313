{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve, classification_report, confusion_matrix\n",
    "\n",
    "# Keras and TensorFlow Imports\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'sample_1_6.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='model12.keras', \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True, \n",
    "    verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.8, \n",
    "    patience=2, \n",
    "    min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImageWidth</th>\n",
       "      <th>OriginalImageHeight</th>\n",
       "      <th>OriginalImagePixelSpacing_x</th>\n",
       "      <th>OriginalImagePixelSpacing_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000013_005.png</td>\n",
       "      <td>Emphysema|Infiltration|Pleural_Thickening|Pneu...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>060Y</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000013_026.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>057Y</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000017_001.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>077Y</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000030_001.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>079Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000032_001.png</td>\n",
       "      <td>Cardiomegaly|Edema|Effusion</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>055Y</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index                                     Finding Labels  \\\n",
       "0  00000013_005.png  Emphysema|Infiltration|Pleural_Thickening|Pneu...   \n",
       "1  00000013_026.png                             Cardiomegaly|Emphysema   \n",
       "2  00000017_001.png                                         No Finding   \n",
       "3  00000030_001.png                                        Atelectasis   \n",
       "4  00000032_001.png                        Cardiomegaly|Edema|Effusion   \n",
       "\n",
       "   Follow-up #  Patient ID Patient Age Patient Gender View Position  \\\n",
       "0            5          13        060Y              M            AP   \n",
       "1           26          13        057Y              M            AP   \n",
       "2            1          17        077Y              M            AP   \n",
       "3            1          30        079Y              M            PA   \n",
       "4            1          32        055Y              F            AP   \n",
       "\n",
       "   OriginalImageWidth  OriginalImageHeight  OriginalImagePixelSpacing_x  \\\n",
       "0                3056                 2544                        0.139   \n",
       "1                2500                 2048                        0.168   \n",
       "2                2500                 2048                        0.168   \n",
       "3                2992                 2991                        0.143   \n",
       "4                2500                 2048                        0.168   \n",
       "\n",
       "   OriginalImagePixelSpacing_y  \n",
       "0                        0.139  \n",
       "1                        0.168  \n",
       "2                        0.168  \n",
       "3                        0.143  \n",
       "4                        0.168  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sample_labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Finding Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['Finding Labels'].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['No_Finding'] = df['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)\n",
    "df['Finding Labels'] = df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        df[c_label] = df['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0).astype(int)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['View Position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Patient ID','OriginalImage[Width',\n",
    "       'Height]', 'OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.drop(['Image Index','Finding Labels','Follow-up #','Patient Age'],axis=1).columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Finding Labels',axis=1,inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Patient Gender'].replace({'M': 1, 'F': 0}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.drop(['Image Index','Follow-up #','Patient Age'],axis=1).columns\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(cols)):\n",
    "        sns.histplot(x=cols[i], data=df, color='#ff9248', ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {cols[i]}')\n",
    "        axes[i].set_xlabel(cols[i])\n",
    "        axes[i].set_ylabel('Count')\n",
    "\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'D:\\\\Downloads\\\\xrays\\\\images'\n",
    "image_files = os.listdir(images_dir)\n",
    "age_gt_100 = df[df['Patient Age'] > 100]['Image Index'].tolist()\n",
    "removed_num = 0\n",
    "for filename in image_files:\n",
    "    if filename in age_gt_100:\n",
    "        file_path = os.path.join(images_dir, filename)\n",
    "        os.remove(file_path)\n",
    "        removed_num += 1\n",
    "df = df[~df['Image Index'].isin(age_gt_100)]\n",
    "print(removed_num,'images removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Patient Age'].sort_values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.set_style('whitegrid')\n",
    "sns.histplot(data=df, x='Patient Age', bins=range(df['Patient Age'].min(), min(df['Patient Age'].max(), 100) + 5, 5),\n",
    "             hue='Patient Gender', multiple='stack', palette='Set1', kde=True)\n",
    "plt.title(f'Distribution of Patients Ages by Gender')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(range(0, 101, 5))\n",
    "\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_cols = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion',\n",
    "       'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule',\n",
    "       'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "counts = df[case_cols].sum()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=counts.index, hue=counts.index, y=counts.values,palette='husl')\n",
    "plt.title('Findings Counts')\n",
    "plt.xlabel('Findings')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Hernia','Follow-up #'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['No_Finding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xrays1_6.csv'\n",
    "if not os.path.exists(filename):\n",
    "    df.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_files(src_dir, dst_dir, size=(224,224)):\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    files = os.listdir(src_dir)\n",
    "    total_files = len(files)\n",
    "    print(\"Found {} files\".format(total_files))\n",
    "\n",
    "    for i, file in enumerate(files, start=1):\n",
    "        img_path = os.path.join(src_dir, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resized_img = cv2.resize(img,(224,224))\n",
    "        output_path = os.path.join(dst_dir, file)\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"Skipping {file} as it already exists.\")\n",
    "            continue\n",
    "        \n",
    "        cv2.imwrite(output_path, resized_img)\n",
    "        if i%(total_files//20) == 0 or i == total_files:\n",
    "            print(f\"{i}/{total_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'D:\\\\Downloads\\\\xrays'\n",
    "output_dir = main_dir+'\\\\images'\n",
    "images_dir = main_dir+'\\\\raw'\n",
    "res_image_size = (224,224)\n",
    "for dir in os.listdir(images_dir):\n",
    "    input_dir = os.path.join(images_dir,dir,'images')\n",
    "    print(str(input_dir))\n",
    "    resize_files(input_dir,output_dir,res_image_size)\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(main_dir+'\\\\xrays.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = os.listdir(output_dir)\n",
    "print(len(image_files), 'images reshaped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices = df['Image Index'].isin(image_files)\n",
    "valid_df = df[valid_indices]\n",
    "print(valid_df.shape)\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'sample_1_6.csv'\n",
    "if not os.path.exists(file):\n",
    "    valid_df.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xrays1_6.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['No_Finding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['No_Finding', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "       'Effusion', 'Emphysema', 'Fibrosis', 'Infiltration', 'Mass', 'Nodule',\n",
    "       'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "image_folder = 'D:\\\\Downloads\\\\xrays\\\\images' # Folder containing the images\n",
    "image_size = (224, 224, 1)  # Assuming images are resized to (224, 224)\n",
    "norm_img_path = 'img_1_6.npy'\n",
    "y = df[labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_images(df, image_folder, dst, y):\n",
    "    batch_size = 32  # Adjust the batch size as needed\n",
    "\n",
    "    num_images = len(df)\n",
    "    num_batches = num_images // batch_size\n",
    "    if num_images % batch_size != 0:\n",
    "        num_batches += 1\n",
    "\n",
    "    # Create folders for x_train, y_train, x_val, and y_val batches\n",
    "    os.makedirs(os.path.join(dst, \"x_trains\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst, \"y_trains\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst, \"x_vals\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dst, \"y_vals\"), exist_ok=True)\n",
    "\n",
    "\n",
    "    for batch_index in range(num_batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = min((batch_index + 1) * batch_size, num_images)\n",
    "        \n",
    "        batch_X, batch_y = [], []\n",
    "        for image_filename, label in zip(df['Image Index'].iloc[start_index:end_index], y[start_index:end_index]):\n",
    "            img_path = os.path.join(image_folder, image_filename)\n",
    "            img = load_img(img_path, color_mode='grayscale')\n",
    "            img = img_to_array(img)\n",
    "            batch_X.append(img / 255)\n",
    "            batch_y.append(label)\n",
    "\n",
    "        if batch_index % (num_batches // 20) == 0 or batch_index == num_batches - 1:\n",
    "            print(f\"Batch: {batch_index + 1}/{num_batches}\")\n",
    "\n",
    "        x_train_batch, x_val_batch, y_train_batch, y_val_batch = train_test_split(\n",
    "            np.array(batch_X), np.array(batch_y),\n",
    "            test_size=0.3,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Save each batch to separate files in respective folders\n",
    "        np.save(os.path.join(dst, \"x_trains\", f\"x_train_batch_{batch_index}.npy\"), x_train_batch)\n",
    "        np.save(os.path.join(dst, \"y_trains\", f\"y_train_batch_{batch_index}.npy\"), y_train_batch)\n",
    "        np.save(os.path.join(dst, \"x_vals\", f\"x_val_batch_{batch_index}.npy\"), x_val_batch)\n",
    "        np.save(os.path.join(dst, \"y_vals\", f\"y_val_batch_{batch_index}.npy\"), y_val_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:\\\\Downloads\\\\xrays'\n",
    "#load_and_process_images(df, image_folder, folder, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataLoader:\n",
    "    def __init__(self, image_folder, datagen, image_size=(224, 224, 3), batch_size=32):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.datagen = datagen\n",
    "\n",
    "    def load_and_augment_images(self, df):\n",
    "        X = []\n",
    "        num_images = len(df)\n",
    "        for i in range(0, num_images, self.batch_size):\n",
    "            print(f'{i}/{num_images}')\n",
    "            batch_images = []\n",
    "            for image_filename in df['Image Index'].iloc[i:i+self.batch_size]:\n",
    "                img_path = self.image_folder + image_filename\n",
    "                img = load_img(img_path, target_size=image_size)\n",
    "                img = img_to_array(img)\n",
    "                batch_images.append(img / 255.0)\n",
    "            batch_images = np.array(batch_images)\n",
    "\n",
    "            augmented_images = []\n",
    "            for batch_img in batch_images:\n",
    "                augmented_img = self.datagen.random_transform(batch_img)\n",
    "                augmented_images.append(augmented_img)\n",
    "            augmented_images = np.array(augmented_images)\n",
    "\n",
    "            if len(X) == 0:\n",
    "                X = augmented_images\n",
    "            else:\n",
    "                X = np.vstack((X, augmented_images))\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history,  metric_acc='accuracy'):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('Cross Entropy Loss')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[metric_acc],'r-x', label=\"Train Accuracy\")\n",
    "    ax.plot(history.history['val_'+metric_acc],'b-x', label=\"Validation Accuracy\")\n",
    "    ax.legend()\n",
    "    ax.set_title('Accuracy')\n",
    "    ax.grid(True)\n",
    "\n",
    "def display_roc(roc_auc , fpr, tpr, class_num, model_name=''):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(class_num):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve (class {}) (AUC = {:.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')                                                                                                                   \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve of {}'.format(model_name))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiclass_roc(y, y_pred, class_num, model_name='', show=True):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    print(y.shape)\n",
    "    print(y_pred.shape)\n",
    "    for i in range(class_num):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y[:,i], y_pred[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    if show:    display_roc(roc_auc,fpr,tpr,class_num,model_name)\n",
    "    else: return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty = 0.0001\n",
    "l2_penalty = 0.0001\n",
    "model_name = 'xray_model1_6'\n",
    "label_used = [0,1,5,8,9,10]\n",
    "model = Sequential(name=model_name)\n",
    "\n",
    "#Input\n",
    "model.add(Input(shape=(224,224,1)))\n",
    "\n",
    "#Conv1\n",
    "model.add(Conv2D(32, (5, 5), strides=(1,1), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=l1_penalty,l2=l2_penalty)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#MaxPool1\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Conv2\n",
    "model.add(Conv2D(64, (5, 5), strides=(1,1), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=l1_penalty,l2=l2_penalty)))\n",
    "model.add(BatchNormalization())\n",
    "#MaxPool2\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Conv3\n",
    "model.add(Conv2D(128, (5, 5), strides=(1,1), activation='relu', padding='same', kernel_regularizer=l1_l2(l1=l1_penalty,l2=l2_penalty)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#MaxPool3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#Final Classification\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.0001)\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "acc_metric = 'binary_accuracy'\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=1, \n",
    "    min_lr=0.000001)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=model_name+'.keras', \n",
    "    monitor='val_'+acc_metric, \n",
    "    save_best_only=True, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_files(src, name, samples):\n",
    "    print(src)\n",
    "    data = []\n",
    "    for idx in samples:\n",
    "        data.append(np.load(os.path.join(src, name+f'{idx}.npy')))\n",
    "    return np.concatenate(data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(folder, \"x_train.npy\")):\n",
    "    np.random.seed(42)\n",
    "    n = len(os.listdir(os.path.join(folder, \"x_trains\")))\n",
    "    sample_n = 500\n",
    "    file_indices = np.arange(n)\n",
    "    sample_indices = np.random.choice(file_indices,size=sample_n,replace=False)\n",
    "    sample_indices = np.sort(sample_indices)\n",
    "    x_train = load_npy_files(os.path.join(folder, \"x_trains\"),'x_train_batch_',sample_indices)\n",
    "    y_train = load_npy_files(os.path.join(folder, \"y_trains\"),'y_train_batch_',sample_indices)\n",
    "    x_val = load_npy_files(os.path.join(folder, \"x_vals\"),'x_val_batch_',sample_indices)\n",
    "    y_val = load_npy_files(os.path.join(folder, \"y_vals\"),'y_val_batch_',sample_indices)\n",
    "\n",
    "    np.save(os.path.join(folder, \"x_train.npy\"),x_train)\n",
    "    np.save(os.path.join(folder, \"y_train.npy\"),y_train)\n",
    "    np.save(os.path.join(folder, \"x_val.npy\"),x_val)\n",
    "    np.save(os.path.join(folder, \"y_val.npy\"),y_val)\n",
    "else:\n",
    "    x_train = np.load(os.path.join(folder, \"x_train.npy\"))\n",
    "    y_train = np.load(os.path.join(folder, \"y_train.npy\"))\n",
    "    x_val = np.load(os.path.join(folder, \"x_val.npy\"))\n",
    "    y_val = np.load(os.path.join(folder, \"y_val.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(os.listdir(os.path.join(folder, \"x_trains\")))\n",
    "print(n)\n",
    "sample_n = 500\n",
    "file_indices = np.arange(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X Train shape:',x_train.shape)\n",
    "print('y Train shape:',y_train.shape)\n",
    "print('X Validation shape:',x_val.shape)\n",
    "print('y Validation shape:',y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[acc_metric])\n",
    "\n",
    "try:\n",
    "    flow = datagen.flow(\n",
    "        x=x_train, \n",
    "        y=y_train[:,[0]], \n",
    "        batch_size=batch_size)\n",
    "    training_time = time()\n",
    "    history = model.fit(\n",
    "        flow, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        validation_data=(x_val, y_val[:,[0]]),\n",
    "        callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "    training_time = time() - training_time\n",
    "except MemoryError:\n",
    "    print(\"Memory Error occurred during training.\")\n",
    "    del history\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('xray_model1_6.keras')\n",
    "y_pred = model.predict(x_val).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_val[:,label_used],y_pred,len(label_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history,acc_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "y_true_classes = y_val[:, [0, 1, 5, 8]].argmax(axis=-1)\n",
    "class_report = classification_report(y_true_classes, y_pred_classes,output_dict=True)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_df = pd.DataFrame(class_report).transpose()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(cr_df.iloc[:-1, :-1], annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title('Classification Report of Top 4 Labels')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"coolwarm\")\n",
    "plt.title('Confusion Matrix of Top 4 Labels')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
