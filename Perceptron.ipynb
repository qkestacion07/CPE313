{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LGwJzMXaKssi"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "    def __init__(self, i, w):\n",
        "        if len(w)!=len(i):\n",
        "            print(\"inputs and weight does not match\")\n",
        "            return\n",
        "        self.inputs = i\n",
        "        self.weights = w\n",
        "        self.output = 0\n",
        "        self.previouses = None\n",
        "        self.linear_combiner()\n",
        "\n",
        "    def linear_combiner(self):\n",
        "        \"\"\"\n",
        "        inputs : list\n",
        "        gets input or set of inputs from the network\n",
        "        \"\"\"\n",
        "        for i in range(len(self.inputs)):\n",
        "            self.output += self.inputs[i]*self.weights[i]\n",
        "        return self.activation()\n",
        "\n",
        "    def activation(self):\n",
        "        \"\"\"\n",
        "        Uses ReLU - piecewise linear function that will output the input directly \n",
        "        if it is positive, otherwise, it will output zero        \n",
        "        \"\"\"\n",
        "        if self.output < 0:\n",
        "            self.output = 0\n",
        "        return self.output\n",
        "\n",
        "    def add_previous(self, neuron):\n",
        "        if self.previouses is None:\n",
        "            self.previouses = [neuron]\n",
        "        else:\n",
        "            self.previouses.append(neuron)\n",
        "        \n",
        "        self.inputs.append(neuron.inputs)\n",
        "        self.weights.append(neuron.weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy_os6JvMVPT",
        "outputId": "65b5a80a-a593-48d2-949d-d3b9914bc2d5"
      },
      "outputs": [],
      "source": [
        "def neuron_table(inputs, weights):\n",
        "    \"\"\"\n",
        "    inputs : list - array of numbers from previous layer or the input\n",
        "    weights : list - array of numbers from the link of the inputs\n",
        "\n",
        "    Displays the tally of computation of each node\n",
        "    \"\"\"\n",
        "    print(\"Input\\tWeight\\tProduct\\tReLU\\tCurrent Sum\")\n",
        "    sum_of_prod = 0\n",
        "    for i in range(len(inputs)):\n",
        "        product = inputs[i]*weights[i]\n",
        "        sum_of_prod += product if product > 0 else 0\n",
        "        print(inputs[i],'\\t',weights[i],'\\t',product,end='\\t')\n",
        "        print(product if product > 0 else 0,\"\\t\",sum_of_prod)\n",
        "    print(\"SUM of products:\",sum_of_prod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = [5,6,7,8,9]\n",
        "weights_1 = [1,3,5,7,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input\tWeight\tProduct\tReLU\tCurrent Sum\n",
            "5 \t 1 \t 5\t5 \t 5\n",
            "6 \t 3 \t 18\t18 \t 23\n",
            "7 \t 5 \t 35\t35 \t 58\n",
            "8 \t 7 \t 56\t56 \t 114\n",
            "9 \t 9 \t 81\t81 \t 195\n",
            "SUM of products: 195\n",
            "\n",
            "Neuron 1: 195\n"
          ]
        }
      ],
      "source": [
        "n1 = Neuron(inputs,weights_1)\n",
        "\n",
        "neuron_table(inputs,weights_1)\n",
        "print('\\nNeuron 1:',n1.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The product of the first input with its weight is 5. The second is 18; third is 35; 4th is 56; and the 5th is 81. Upon using ReLU, their value remained the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmeUnKeMOi4N",
        "outputId": "6ac88064-9c7a-483b-e8e1-06a0c86f7196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input\tWeight\tProduct\tReLU\tCurrent Sum\n",
            "5 \t 1 \t 5\t5 \t 5\n",
            "6 \t 3 \t 18\t18 \t 23\n",
            "7 \t 5 \t 35\t35 \t 58\n",
            "8 \t 7 \t 56\t56 \t 114\n",
            "9 \t 9 \t 81\t81 \t 195\n",
            "SUM of products: 195\n",
            "\n",
            "Neuron 2: 195\n"
          ]
        }
      ],
      "source": [
        "n2 = Neuron(inputs,weights_1)\n",
        "\n",
        "neuron_table(inputs,weights_1)\n",
        "print('\\nNeuron 2:',n2.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input\tWeight\tProduct\tReLU\tCurrent Sum\n",
            "5 \t 1 \t 5\t5 \t 5\n",
            "6 \t 3 \t 18\t18 \t 23\n",
            "7 \t 5 \t 35\t35 \t 58\n",
            "8 \t 7 \t 56\t56 \t 114\n",
            "9 \t 9 \t 81\t81 \t 195\n",
            "SUM of products: 195\n",
            "\n",
            "Neuron 3: 195\n"
          ]
        }
      ],
      "source": [
        "n3 = Neuron(inputs,weights_1)\n",
        "\n",
        "neuron_table(inputs,weights_1)\n",
        "print('\\nNeuron 3:',n3.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2RNrKMtfZxM"
      },
      "source": [
        "ReLU works\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 2, 1]\n"
          ]
        }
      ],
      "source": [
        "from random import randint\n",
        "\n",
        "#Random weights for the output neuron\n",
        "output_weights = [randint(-1,5) for _ in range(3)]\n",
        "print(output_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl_OYrKqOvpz",
        "outputId": "9b3bfb02-77c2-4da6-e240-50e2c11f1e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input\tWeight\tProduct\tReLU\tCurrent Sum\n",
            "195 \t 0 \t 0\t0 \t 0\n",
            "195 \t 2 \t 390\t390 \t 390\n",
            "195 \t 1 \t 195\t195 \t 585\n",
            "SUM of products: 585\n",
            "\n",
            "Output neuron: 585\n"
          ]
        }
      ],
      "source": [
        "output_n = Neuron([n1.output, n2.output, n3.output],output_weights)\n",
        "\n",
        "neuron_table([n1.output, n2.output, n3.output],output_weights)\n",
        "print('\\nOutput neuron:',output_n.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New Perceptron Task\n",
        "Create a network with feed forward with multiple neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class Neuron:\n",
        "    def __init__(self, inputs, weights, activation):\n",
        "        self.inputs = inputs\n",
        "        self.weights = weights\n",
        "        self.output = 0\n",
        "        self.act = activation\n",
        "        self.linear_combiner()\n",
        "\n",
        "    def linear_combiner(self):\n",
        "        \"\"\"\n",
        "        inputs : list\n",
        "        gets input or set of inputs from the network\n",
        "        \"\"\"\n",
        "        for i in range(len(self.inputs)):\n",
        "            self.output += self.inputs[i]*self.weights[i]\n",
        "        return self.activation()\n",
        "\n",
        "    def activation(self):\n",
        "        \"\"\"\n",
        "        Uses ReLU - piecewise linear function that will output the input directly \n",
        "        if it is positive, otherwise, it will output zero \n",
        "        Uses sigmoid - takes any real value as input and outputs values in the range of 0 to 1       \n",
        "        \"\"\"\n",
        "        if self.act == 'ReLU':\n",
        "            if self.output < 0:\n",
        "                self.output = 0\n",
        "        elif self.act == 'sigmoid':\n",
        "            self.output = 1 / (1 + np.exp(-self.output))\n",
        "        else:\n",
        "            print(\"Invalid activation function\")\n",
        "            return None\n",
        "        return self.output\n",
        "\n",
        "class Layer:\n",
        "    def __init__(self, num_neurons: int, inputs: list, weights: list, activation='sigmoid'):\n",
        "        self.neurons = [Neuron(inputs, weights, activation) for _ in range(num_neurons)]\n",
        "    \n",
        "    def get_output(self):\n",
        "        outputs = []\n",
        "        for neuron in self.neurons:\n",
        "            outputs.append(neuron.output)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Redefined the neuron to have more activation function\n",
        "- Created a layer class that has the collection of neurons (They have identical activation function and neighboring layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input\tWeight\tInput Layer\tWeight\tOutput Layer\n",
            "5\t1\t195\t\t2\t1.0\n",
            "6\t3\t195\t\t1\t\n",
            "7\t5\t195\t\t3\t\n",
            "8\t7\t195\t\t2\t\n",
            "9\t9\t195\t\t1\t\n"
          ]
        }
      ],
      "source": [
        "inputs = [5,6,7,8,9]\n",
        "weights_1 = [1,3,5,7,9]\n",
        "output_weights = [np.random.randint(-1,4) for _ in range(5)]\n",
        "\n",
        "input_layer = Layer(5, inputs, weights_1, activation=\"ReLU\")\n",
        "output_layer = Layer(1, input_layer.get_output(), output_weights, activation=\"sigmoid\")\n",
        "\n",
        "print(\"Input\\tWeight\\tInput Layer\\tWeight\\tOutput Layer\")\n",
        "for i in range(5):\n",
        "    print(inputs[i],end='\\t')\n",
        "    print(weights_1[i],end='\\t')\n",
        "    print(input_layer.get_output()[i],end='\\t\\t')\n",
        "    print(output_weights[i],end='\\t')\n",
        "    if i==0:\n",
        "        print(output_layer.get_output()[0],end=\"\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first three columns shown are identical to the displayed output of the three prototype neurons above. All neurons in the input layer have identical values (195). The random weight assigned with random randint were paired with the 5 neuron values. Since the sum of all the the produce of the paired input layer and weight is huge, the sigmoid activation function return 1."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
